<html>
<head>
<link rel="stylesheet" type="text/css" href="/~donna/style.css" title="style1">
<style type=text/css>
DIV.ans { margin: 3px 0px 10px 3px; padding: 4px; border: 1px dashed black;
 font-family: helvetica; font-size: 10pt; font-weight: 500; color: #777;
 background-color: #DEE; padding-right: 5px; height: 50px; width: 600px; }

DIV.box { position: relative; float: left; margin: 0px 0px 2px 0px; 
 padding: 4px; # border: 1px dashed black;
 font-family: helvetica; font-size: 10pt; font-weight: 500; color: #19193A;
 background-color: #eee; padding-right: 0px; width: 450px; height: 60px; }
h5 { background-color: yellow; width: 300px;}
li { height: 1.5em;}
BODY { margin: 2% 20% 5% 5%;  background-color: white; }
</STYLE>

</head>
<body>
<h4>CMPS 450 Lecture Notes - Week 3 </h4>
<h3> Chapter 3.1 - 3.5  "Lexical Analysis"</h3>

<b>resources:</b><br>
<a href="https://en.wikipedia.org/wiki/ANSI_C">ANSI C Language Reference</a><br>
<a href="http://www.gnu.org/software/gnu-c-manual/gnu-c-manual.html">GNU C Language Reference</a><br>
<a href="https://msdn.microsoft.com/en-us/library/fw5abdx6.aspx">Microsoft C Language Reference</a><br>
<p>

To augment the material in this chapter you may find this text useful:   
<a href="http://math.hws.edu/FoundationsOfComputation/">Foundations of 
		Computation</a>. This is
  a free textbook for a 1-semester course in theoretical computer science.
 This text is not about compilers per se but covers the underlying
 theory. See Ch 3 "Regular Expressions and FSA's" and Ch 4 "Grammars."

 <p/>	

 This half of chapter 3 of the Dragon book presents
 the algorithms and  computational theory used by 
  a lexical analyzer. 

<h4> Ch.3.1 "Role of Lexical Analyzer"</h4>

What the lexical analyzer does:
<pre>
1. scan the input stream for lexemes
2. categorize lexemes into token classes (might access symbol table)
3. possibly add entry to symbol table 
4. interact with parser
5. take care of errors during steps #1 and #2
</pre>
How many lexemes are in this chunk of C code?
<pre>for (j=0; j > COL; j++){
          /* compute offset */ 
          offset = (i * COL) + j;
          /* find value */ 
          *i_array++ = pow(2,i) + j;
      }
</pre>
There are 14 + 10 + 13 + 1 = 38 lexemes. Following C
 syntax, how many different tokens types are there?
<p>
There are only 6 different token types:
keyword, punctuator, operator, identifier, number, comment


<h4> Ch.3.2 "Input Buffering"</h4>

<i>Aside. You won't implement any buffering algorithms since you are generating
 your scanner with lex. </i>
The problem addressed here is how to efficiently scan for lexemes
 when you might need more than one character lookahead.
 Notation: 
 <i>forward</i> marks current character scanned and 
 <i>lexemeBegin</i>
 marks start of current lexeme. EOF is a special character (often -1)
  that marks end of input.
 <p>

 2-buffer algorithm to reload buffers with equal sized buffers and
  EOF sentinels at end of both buffers :
<pre><tt>
       switch (*forward++) {
              case eof:
                   if (forward is at end of first buffer) {
                          reload second buffer;
                          forward = beginning of second buffer:
                   }
                   else if (forward is at end of 2nd buffer) {
                          reload first buffer;
                          forward = beginning of first buffer;
                  }
                  else /* eof within a buffer marks end of input */
                          terminate lexical analysis;
                  break;
             case other characters
      }
</tt></pre>
In a 2-buffer scheme this statement<pre>
   	 n =(x- y)*5;
</pre>
is read into two buffers of size 8. The second EOF buffer below marks
the end of actual input: 
<pre><tt>
     buffer 1                   buffer 2
     |n|space|=|(|x|-|space|EOF|y|)|*|5|;|EOF| | | |EOF|

</tt></pre>
In this scheme the two pointers in the lookahead buffer 
may cross over each other:
<pre><tt>
     | ......EOF..EOF|........EOF
        ^forward           ^lexemeBegin
</tt></pre>

<h4> Ch.3.3 "Specification of Tokens"</h4>

This section outlines the formalism for lexical analysis; e.g., how to
 identify and classify the tokens in a language.

<p><b>Terminology and Notation</b><p/>

<li> the alphabet &Sigma; is the finite set of terminal symbols 
</li>
<li> a string (also called word or sentence) is a finite sequence of symbols 
 from &Sigma;

<li>the language <b>L</b> 
is a set of strings (the set may be finite or infinite)
</li>
<li>  The null set &Phi; or {}, is a
 language with no elements (empty language)
</li>
<li> 
 &epsilon; or &lambda; is the empty string </li>
<li> { &lambda;}  is the language contain the empty string</li>
<li> {} is the empty language </li>


 <p/>
 We now define operations on 
 strings and operations on language. A string is a
 either the empty string or 1 or more terminals from the alphabet.
 A language L is a set that contains the strings of L.
 Operations on strings differ from operations on languages.

 <p>
<b>Operations on Strings </b>

<p/>
Concatenation is the only operation that can be applied to
 the strings of a language.
  String concatenation can be expressed as
<pre>     st   # string s glued to string t</pre> 

or with the exponentiation operator: 

<pre>     s^0 = &epsilon;, s^1 = s, s^2 = ss,...  </pre>
The empty string is the identity
  under concatentation; e.g. &epsilon;s = s&epsilon; = s, for any string s.
	<p>
<b>Operations on Languages</b>
<p/>
A language is a set.
 Operations on languages 
	 are set operations. There are three language operations: 
<pre>      union, concatenation and closure   </pre>
The union of
 two languages L and M is the union of the two sets L and M. 
  L &cup; M contains string s if s is a member of L or s is
 a member or M.
 <p/>
<p>
 String concatenation glues two or more strings together in the order 
 in which they appear in the operation; e.g., st is the concatenation of
 string s followed by string t. When you apply concatenation to a language,
 you are applying the string operation to ALL strings in the set of L and M.
</p>
<p>
The concatenation of two languages 
	L and M (denoted as LM) is the set of all strings formed by taking a string
	from L and a string from M and concatenating them. 
	L^n is defined as the concatenation of each string in L with each string
 in L n times.  L^0 is {&epsilon;}. Note that L^0 is not an empty set! L^0
 is the set containing the null string.
<p>
 A string operation on L and M  is the cartesian production of the operation 
 applied to each member of L with each member of M. 
<p/>
 Kleene closure (*) is the union of of all concatenations of the language
 L with itself, including L^0. 
<p/>
The positive closure of L (+) is the Kleene closure excluding L^0. 
<pre> 
OPERATION                 DEFINITION AND NOTATION
Union of L and M          L &cup; M = { s | s &isin; L or s &isin; M }
Concatenation of L and M  LM = { st | s &isin; L and t &isin; M } 
Kleene closure of L       L* = { the union of L^i, for i from 0 to &#8734; }
Positive closure of L     L+ = { the union of L^i, for i from 1 to &#8734; }
</pre>

<p/>
<b>Examples</b>
<pre>
Let V be the set of vowels {a, e, i, o, u}. |V| = 5
Let C be the set of consonents {b, c, d, f, ... z}. |C| = 21.

V &cup; C, the union of V and C, is the set of letters { a, b, c, ..., x, y, z }
|V &cup; C| =  |V| + |C| =  5 + 21 = 26  // '|S|' is the  cardinality of set S

VC is the set of all vowels concatenated with all consonents 
VC = { ab, ac, ad, af, ..., eb, ec, ed, ... ea, ... uz }
|VC| = 5 * 21 = 105

V^4 is the concatenation of of all vowels with all other vowels 4 times, thus
    { aaaa, aaae, aaai, aaao, aaau, 
      aaea, aaee, aaei, aaeo, aaeu,
			 ...
      auuu, euuu, iuuu, ouuu, uuuu }
        
|V^4| = |V|^4 = 5^4 ; V^4 is the permutation of 5 things taken 4 at a time
where items can be repeated

V* is the set of strings of all possible concatenations of vowels from V, 
including &epsilon; 

V+ is the set of strings of all possible concatenations of vowels from V,
excluding V^0 (the empty string)

V(V &cup; C)* is the concatenation of all vowels with any vowel or consonent 
concatenated with any vowel or consonent zero or more times.

The above formalism provides the basis of Regular Expressions. You can easily
build more complicated expressions from here. For example, regex 

      V(V &cup; C)*, where | is the union operator.

denotes this set:

     [a,e,i,o,u]([a,e,i,o,u] | [b-d,f-h,j-n,p-t,v-z])*    

The transition from the formalism to the language of regular expressions is:

1. &epsilon; is a regex and L(&epsilon;) is {&epsilon;}

2. If s is a symbol in &Sigma; then s is a regular expression and L(s) = {s}.

From this basis we add concatenation, union, * and + operators, and you can 
inductively build any regular language:

1. (r) | (s)  // means L(r) &cup; L(s)
2. (r)(s)     // means the concatenation L(r)L(s)
3. (r)*       // means (L(r))*
4. (r)        // means L(r)

Use precedence and associativity conventions to drop parentheses:

operator precedence highest to lowest:
*               // Kleene closure is left associative
concatenation   // left associative
|               // union is left associative 

</pre>
<b>Examples</b>
<pre>
Let L(a) = a and L(b) = b. Then

1. regular expression a | b denotes language { a, b }
2. (a|b)(a|b) denotes { aa, ab, ba, bb }
3. a* denotes { &epsilon;, a, aa, aaa, aaaa, ..... }
4. (a|b)* is the language of &epsilon and all possible strings of a and b 
5. (a*|b*)* denotes the same language as #4 -- the regexes are equivalent
6. a|a*b denotes the language { a, b, ab, aab, aaab, ... }


LAWS for regular expression. Let r, s, t be arbitrary languages 

r|s = s|r
r|(s|t) = (r|s)|t
r(st) = (rs)t
r(s|t) = rs|rt; (s|t)r = sr|tr
&epsilon;r = r&epsilon; = r
r* = (r|&epsilon;)*
r** = r*

</pre>
<b>Regular definitions and extensions were added to make notation easier:</b>
<pre>

letter_ -> a | b | ... | z | A | B | ... | Z | _ 
digit   -> 0 | 1 | 2 | ... | 9
id      -> letter_( letter_ | digit )*


+    // one or more instances; the positive closure of *; r* = r*|&epsilon; 
?    // zero or one instance; r& = r | &epsilon;
[]   // character class; [a-z] is a|b|...|z.
</pre>

<b>Examples</b>
<pre>
 letter_ -> [A-Za-z_]
 digit   -> [0-9]
 id      -> letter_( letter_ | digit )* 

What language does this regular definition define?
 digit  -> [0-9]
 digits -> [0-9]+
 number -> digits (. digits)? ( E[+-]? digits)?

</pre>
Lex supports all the normal extensions including:

<pre>
EXPRESSION   MATCHES                            EXAMPLE
\c           character c literally              \$
.            any character but a newline        a.*b
r | s        r or s                             a | b
r{m,n}       between m and n occurrences of r   a{1,5}
r/s          r when followed by s               abc/123
[^r]         anything but r ( this is a         [^abc]
             a complemented character class )   
</pre>
String Terminology: <br>
A <u>prefix</u> of string s is any string obtained by removing zero or more
 symbols from the *end* of s. The prefixes of ban = {ban, ba, b, &epsilon;} 
<p>
A <u>suffix</u> of string s is any string obtained by removing zero or more
symbols from the *beginning* of s. The suffixes of ban = {ban, an, n, &epsilon;} 
<p>
A <u>substring</u> of string s is any string obtained by removing zero or more
 symbols from the beginning or the end of s.  The
  substrings of ban = {&epsilon;, b, n, ba, an, ban}
<p>
The set of <u>proper</u> prefixes, suffixes, or substrings of s does not
include s or &epsilon;
<p>
A <u>subsequence</u> of s is any string formed by deleting zero  or more
not necessarily consecutive positions of s; e.g., baan is a subsequence of
banana. The subsequences of ban = {&epsilon;, b, a, n, ba, bn, an, ban}
If n is the length of s, then the cardinality of the set of subsequences is  
 2^n - 1.
<p>
 

<h4> Ch.3.4 "Recognizing Tokens"</h4>

The most important job of the lexical analyzer (aka scanner or lexer) 
 is to
recognize lexemes and to categorize them into tokens.
This section covers a scanner recognition algorithm
  based on transition diagrams. 
<p>
<b>Transition Diagrams</b><p>

 Transition diagrams are flowcharts that depict
 how the scanner tests for a match on the regex 
 from the beginning of input to the end of input.
 <p>
 Lex generates a scanner for you based on the regular expressions that
 you supply for each token. Under the covers, Lex builds
 and implements a transition diagram for each regex.
 The behavior of a lex scanner as it evaluates an input stream is
 based on the transition diagrams. 
 To code a scanner manually, constructing
  a transition diagram and then implementing it is the best strategy.
<p>
 A transition diagram is a directed graph with
 a  finite number of states (vertices) in the graph. A state can be
 connected to another state by a directed edge. States represent where 
 the scanner is in the regex based on the value of a single character in the 
  input string. Edges are labeled with the input character
 that moves you from the current state to the next state.
 Transition diagrams are deterministic. In other words,
 there is only one choice when moving from state to state based on 
 a particular input character (it is never the case that the scanner
 arbitrarily picks the next state to move to). A transition diagram 
 can be represented in table form
  where rows denote 
  the states and columns denote the input characters.
<p>
From the finite set of states, there is a single start state and at least
 one accepting state. States are uniquely labeled beginning
 from the start state that is labeled '0' (zero) by default.
 <p>
Example. <pre>
&Sigma; = {a, b}   </pre>
Provide a regex for the language of
 all strings over {a, b} that contain the substring
 aaa. No other constraints.
<pre>
regex = /(a|b)*aa(a|b)*/
</pre>
Draw a transition diagram for your regex.
<pre>
       a  b
    0  1  0
    1  2  0
    2  2  2    F = {2}, where F is the set of accepting states
</pre>
Draw a transition diagram for this regex. <pre>
        /(a|b)+aba/

       a  b
    0  1  1 
    1  2  1
    2  1  3
    3  4  1    F = {4}  </pre>

The Failure Function is a way of optimizing pattern matching.
<pre>
 
  
  PATTERN MATCHING ALGORITHM WITH FAILURE FUNCTION
 --------------------------------------------------
              0 1 2 3 4 5 6 7 8 9 10 11 
  input[11]:  a b a b c a b c a b d  e
 --------------------------------------------------
              0 1 2 3 4 5 6
  pattern[6]: a b c a b d e
 --------------------------------------------------
  
            v 
  input:   [a] b a b c a b c a b d e   INITIAL STATE. Start checking at input[i]
  pattern: [a] b c a b d e             and pattern[i] for i=0.
  
              v 
  input:   a [b] a b c a b c a b d e   i++ and compare. we have a match. 
  pattern: a [b] c a b d e
  
                v
  input:   a b [a] b c a b c a b d e   i++. FAIL. What do we do now? Slide the
  pattern: a b [c] a b d e             pattern to input[2] and start over. This
                                       is more efficient than brute-force. 
  
                v
  input:   a b [a] b c a b c a b d e   RESET. slide pattern to input[2]
  pattern:     [a] b c a b d e
  
                  v
  input:   a b a [b] c a b c a b d e   i++. match.
  pattern:     a [b] c a b d e
  
                    v
  input:   a b a b [c] a b c a b d e   i++. match.
  pattern:     a b [c] a b d e
  
                      v
  input:   a b a b c [a] b c a b d e   i++. match.
  pattern:     a b c [a] b d e
  
                        v
  input:   a b a b c a [b] c a b d e   i++. match.
  pattern:     a b c a [b] d e
  
                          v
  input:   a b a b c a b [c] a b d e   i++. FAIL.
  pattern:     a b c a b [d] e
  
                          v
  input:   a b a b c a b [c] a b d e   RESET. alide pattern to input[5] 
  pattern:           a b [c] a b d e
  
                            v
  input:   a b a b c a b c [a] b d e   match.
  pattern:           a b c [a] b d e
  
                              v
  input:   a b a b c a b c a [b] d e   match.
  pattern:           a b c a [b] d e
  
                                v
  input:   a b a b c a b c a b [d] e   match.
  pattern:           a b c a b [d] e
  
                                  v
  input:   a b a b c a b c a b d [e]   match.
  pattern:           a b c a b d [e]   BINGO!
  
  RESET is the Failure Function. It tells you how far to the right you can slide 
  the pattern. The algorithm is essentially to grab the longest proper suffix of 
  input that matches the longest proper prefix of the pattern.
  
  Efficiency.
  How does the efficiency of pattern matching with the Failure Function
  compare to a brute force algorithm?
  
  Let n be the size of the pattern. Let m be the size of the input text. The
  number of comparisons in brute force is thus O(mn). What about FF? This trace
  depicts why FF is O(m) in the worst case and O(n) in the best case:
  
  a b a e c a b c e b d 
  e b d 
          
  a b a e c a b c e b d 
    e b d 
  
  a b a e c a b c e b d 
      e b d 
  
  a b a e c a b c e b d 
        e b d 
  
          v
  a b a e c a b c e b d    With Brute Force RESET back to input[1]!
        e b d              With FF reset to i since NO input suffix matches
                           any prefix in pattern. 
  
          v
  a b a e c a b c e b d 
          e b d 
  
            v
  a b a e c a b c e b d 
            e b d 
  
              v
  a b a e c a b c e b d 
              e b d 
  
                v
  a b a e c a b c e b d 
                e b d 
  
                  v
  a b a e c a b c e b d 
                  e b d 
  
                    v
  a b a e c a b c e b d 
                  e b d 
  
                      v
  a b a e c a b c e b d 
                  e b d   BINGO!
  
  
  ----------------------------------------------------------------
  FF for pattern 'ababaa'
 
  The transition diagram for pattern ababaa is (0 is initial state):

       a        b        a        b        a       a 
  [0] ---> [1] ---> [2] ---> [3] ---> [4] ---> [5] ---> [[6]]


  The failure function (s denotes state): 
 
         a   b   a   b   a  a
  -----,---,---,---,---,---,---
    s  | 1 | 2 | 3 | 4 | 5 | 6                     a   
  -----,---,---,---,---,---,---    s[1] means [0] ---> [1]
  f(s) | 0 | 0 | 1 | 2 | 3 | 1                     b 
  -----'---'---'---'---'---'---    s[4] means [3] ---> [4]
</pre>
  Reason as follows. Assume you are in state 5. In state 5 you are expecting an
  'a' to move you to state 6 but do not get it (you get anything but 'a'). The 
  longest proper suffix on the input string that matches the longest proper 
  prefix in the pattern is 'aba'.
  That takes you to State 3. You continue matching from State 3.
<p>
The data structure for pattern matching 
 with longest-prefix matching 
 is a TRIE (try) rather than a binary tree. For example, assuming
 7 keywords: to, tea, ted, ten, an, in, inn, the trie looks like this:<br>
<img src="./Images/trie.png"> 
<P>A search in trie is O(m), where m is the length of the key.
<p>
How does this compare to a binary search tree? The search tree looks like this:
<br/>
<img src="./Images/binary-tree.png"> 
<P>A search in a binary tree is O(m lg n), where n is number of keywords in the tree and m is the length of the keyword. Why m? Because once you hit the
 node you must do a linear comparison of the keyword to see if it is a match.
<p>
<h4> Ch.3.5 "Using Lex"</h4>

Covered in Lab 02 and beyond.

</body>
</html>
