<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- saved from url=(0050)http://www.cs.csub.edu/~melissa/cs321-w15/hw2.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta http-equiv="content-type" content="txt/html">
  <title>CMPS 321 - Homework 2</title>
</head>

<body>
<h2>Homework 2 - Chapter 5</h2>
Due: Friday January 22, 2016 by 11:59pm PST
<br>
<b>Last Late Day</b>: The assignment will only be accepted late through
11:59pm on Saturday January 24, 2015 so that the solution can be posted for 
people to review before Midterm 1 on Tuesday January 27th.
<ol>
<li>(8 pts) This is a continuation of Question 8 from Homework 1. You are now
going to evaluate two more cache designs: a direct-mapped cache with 4 
instructions per block (block size = 4 words) that stores up to 16 instructions
and a 2-way set associative cache with 4 instructions per block that stores
up to 32 instructions. Both caches will have 4 rows with this setup.
<p>
The main difference between the 2-way set associative cache with 4 
instructions per block and the direct-mapped cache with 4 instructions per 
block is that each row of the 2-way set associative cache contains 2 blocks 
instead of 1 block. The blocks are unrelated except for the fact that they 
map to the same cache row address. 
</p><p>
The cache row address and tag for this cache will be calculated as follows:
</p><pre>   4 instructions per row, 2 bit word offset = address[3:2]
   row number is 2 bits = address[5:4]
   tag is 26 bits = address[31:6]

     31 ... 6|5 4|3 2|1 0
     --------------------
    |  Tag   |Row|   |0 0|  address
     --------------------
                  /|\ /|\
                   |   |___ byte offset
                   |
               word offset
</pre>
The instructions being executed are the same as Homework 1 (note 4000d means
4000 in decimal notation):
<pre>    Address    Instruction
    =======    ============================
    4000d      Loop:   beq $s0, $zero, Exit   # immediate = 6, offset to Exit
    4004d              add $t0, $s0, $s2      # compute read address
    4008d              add $t1, $s0, $s3      # compute write address
    4012d              lw $t2, 0($t0)         # read data
    4016d              sw $t2, 0($t1)         # write data
    4020d              sub $s0, $s0, $s1      # subtract offset
    4024d              j Loop                 # immediate = 1000 which is 4000/4
    4028d      Exit:
</pre>
Fill in the following cache table and state how many cache misses this design
has. Assume that the code starts executing at the Loop: tag, that is executes
for EXACTLY two interations, and that the cache is empty at the start.
<p>
</p><table border="">
<caption><b>Direct Mapped Cache - 4 instructions per block</b></caption>
<colgroup>
  <col width="10*">
  <col width="0*">
  <col width="125">
  <col width="150">
  <col width="150">
  <col width="150">
  <col width="150">
</colgroup>
<tbody><tr>
<th rowspan="2">Row (2 bits)</th>
<th rowspan="2">Valid</th>
<th rowspan="2">Tag (26 bits)</th>
<th colspan="4">Data (4 instructions, 2 bit word offset)</th>
</tr>
<tr>
<th>Word 00</th>
<th>Word 01</th>
<th>Word 10</th>
<th>Word 11</th>
</tr>
<tr>
<td>00 (0)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>01 (1)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>10 (2)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>11 (3)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
</tbody></table>
<p>
</p><table border="">
<caption><b>2-way Associative Cache - 4 instructions per block</b></caption>
<colgroup>
  <col width="10*">
  <col width="0*">
  <col width="125">
  <col width="150">
  <col width="150">
  <col width="150">
  <col width="150">
</colgroup>
<tbody><tr>
<th rowspan="2">Row (2 bits)</th>
<th rowspan="2">Valid</th>
<th rowspan="2">Tag (26 bits)</th>
<th colspan="4">Data (4 instructions, 2 bit word offset)</th>
</tr>
<tr>
<th>Word 00</th>
<th>Word 01</th>
<th>Word 10</th>
<th>Word 11</th>
</tr>
<tr>
<td rowspan="2">00 (0)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td rowspan="2">01 (1)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td rowspan="2">10 (2)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td rowspan="2">11 (3)</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
</tr>
</tbody></table>
<p>
</p></li><li>(2 pts) Cache misses are classified as one of the following: compulsory, 
capacity or conflict. Which of these types of cache misses can be minimized by 
rewriting your code to use less memory? 
</li><li>(2 pts) Assume you have a 2D matrix written in C or C++ which contains
8 rows with 64 integers per row. Your cache block size is 16 bytes and you 
have a 2-way set associative cache containing 8 rows. What would be the miss 
rate if you accessed all of the elements in the matrix column-by-column?
</li><li>(4 pts) Assume you have a cache hierarchy where the L1 hit time is 2ns,
the L2 hit time is 6ns, the L3 hit time is 25ns, and main memory access time
is 100ns. Assume 100 memory accesses occur. What is the average transfer time 
for each of the following scenarios:
<ol type="a">
<li>8% miss rate on L1, 30% miss rate on L2, 50% miss rate on L3
</li><li>3% miss rate on L1, 40% miss rate on L2, 20% miss rate on L3
</li></ol>
</li><li>(4 pts) Page tables and translation lookaside buffers are used for 
managing virtual memory addresses. Assume you have a system with 4KB pages,
4-entry fully associative TLB, and true LRU replacement. 
<p>
Assume the TLB and page table are initially as follows:
</p><p>
</p><table border="" style="float:left">
<caption><b>TLB Initial State</b></caption>
<tbody><tr>
<th>Valid</th>
<th>Tag</th>
<th>Page Number</th>
</tr>
<tr>
<td>1</td>
<td>11</td>
<td>12</td>
</tr>
<tr>
<td>1</td>
<td>7</td>
<td>4</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
<td>6</td>
</tr>
<tr>
<td>0</td>
<td>4</td>
<td>9</td>
</tr>
</tbody></table>
<p>
</p><table border="">
<caption><b>Page Table Initial State</b></caption>
<tbody><tr>
<th>Valid</th>
<th>Physical Page (or on Disk)</th>
</tr>
<tr>
<td>1</td>
<td>5</td>
</tr>
<tr>
<td>0</td>
<td>Disk</td>
</tr>
<tr>
<td>0</td>
<td>Disk</td>
</tr>
<tr>
<td>1</td>
<td>6</td>
</tr>
<tr>
<td>1</td>
<td>9</td>
</tr>
<tr>
<td>1</td>
<td>11</td>
</tr>
<tr>
<td>0</td>
<td>Disk</td>
</tr>
<tr>
<td>1</td>
<td>4</td>
</tr>
<tr>
<td>0</td>
<td>Disk</td>
</tr>
<tr>
<td>0</td>
<td>Disk</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>1</td>
<td>12</td>
</tr>
</tbody></table>
<p>
You access the following stream of virtual addresses:
</p><pre>4669, 2227, 13916, 34587, 48870, 12608, 49225
</pre>
Give the final state of the system (updated TLB and page table).



</li></ol></body></html>